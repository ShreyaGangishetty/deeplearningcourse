{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# We have mnist saved on our disk\n",
    "mnist = np.load('mnist.npz')\n",
    "# open things\n",
    "train_images = mnist['x_train']\n",
    "train_labels = mnist['y_train']\n",
    "train_images = train_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# This is how you flatten in numpy\n",
    "print(train_images.shape)\n",
    "train_images = train_images.reshape(60000, 28 * 28) # see that trick!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.8906 - acc: 0.7555\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.3920 - acc: 0.8905\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.3412 - acc: 0.9030\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3175 - acc: 0.9093\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3021 - acc: 0.9138\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2912 - acc: 0.9172\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.2829 - acc: 0.9193\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.2763 - acc: 0.9219\n",
      "Epoch 9/20\n",
      "19584/60000 [========>.....................] - ETA: 4s - loss: 0.2782 - acc: 0.9218"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-cafabf9b17a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m               metrics=['accuracy']) # this is just so we can see how good the predictions are\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# REPLACE THE DATA WITH MNIST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras # import the framework\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=784)) # INTRODUCE NON-LINEARITY\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "\n",
    "# linear separator bits\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', # a measure of error for multi-category problems, used for knob tweaking\n",
    "              optimizer='sgd', # this is the knob-tuning portion. also standard.\n",
    "              metrics=['accuracy']) # this is just so we can see how good the predictions are\n",
    "\n",
    "model.fit(train_images, to_categorical(train_labels), epochs=20) # REPLACE THE DATA WITH MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find some image.\n",
    "random_image = train_images[7]\n",
    "random_check_image = random_image.reshape(28, 28) # need to do this since we flattened it before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1508fc0b8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJAIBQCIQAKT/A7NLEJVAiOdtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14fa82c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let us plot it.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(random_check_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 921us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(np.array([random_image]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
